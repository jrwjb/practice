{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sklearn.svm.SVC(C=1.0, kernel=’rbf’, degree=3, gamma=’auto_deprecated’, coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, decision_function_shape=’ovr’, random_state=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C\n",
    "错误项的惩罚参数C，浮点型，默认为 1.0，C越大，即对分错样本的惩罚程度越大，因此在训练样本中准确率越高，但是泛化能力降低，越容易产生过拟合。相反，减小C的话，容许训练样本中有一些误分类错误样本，泛化能力强。对于训练样本带有噪声的情况，一般采用后者，把训练样本集中错误分类的样本作为噪声。\n",
    "\n",
    "kernel 核函数类型，字符串类型，默认为rbf。可选参数为：\n",
    "\n",
    "`linear`：线性核函数\n",
    "\n",
    "`poly`：多项式核函数\n",
    "\n",
    "`rbf`：径像核函数/高斯核\n",
    "\n",
    "`sigmod`：sigmod 核函数\n",
    "\n",
    "`precomputed`：核矩阵。`precomputed`表示自己提前计算好核函数矩阵，这时候算法内部就不再用核函数去计算核矩阵，而是直接用你给的核矩阵，核矩阵需要为`n*n`。\n",
    "\n",
    "probability\n",
    "预测时是否使用概率估计，布尔型，默认为 False，这必须在调用fit()之前启用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-3-4df332ed2407>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-3-4df332ed2407>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    class sklearn.svm.LinearSVC(penalty='l2', loss='squared_hinge', dual=True, tol=0.0001, C=1.0, multi_class='ovr', fit_intercept=True, intercept_scaling=1, class_weight=None, verbose=0, random_state=None, max_iter=1000)\u001b[0m\n\u001b[1;37m                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class sklearn.svm.LinearSVC(penalty='l2', loss='squared_hinge', dual=True, tol=0.0001, C=1.0, multi_class='ovr', fit_intercept=True, intercept_scaling=1, class_weight=None, verbose=0, random_state=None, max_iter=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "penalty\n",
    "正则化参数，有 L1 和 L2 两种参数可选，仅 LinearSVC 有。和逻辑回归中地正则惩罚项非常类似，L1 会让决策边界中部分特征的系数 w 被压缩到 0，而 L2 会让每个特征都被分配到一个不为 0 的系数。\n",
    "\n",
    "loss\n",
    "在求解决策边界过程中使用的损失函数，有hinge和squared_hinge两种可选，前者又称 L1 损失，后者称为 L2 损失，默认是是squared_hinge，其中hinge是 SVM 的标准损失，squared_hinge是hinge的平方。\n",
    "\n",
    "dual\n",
    "布尔型，默认是 True。选择让算法直接求解原始的拉格朗日函数，或者求解对偶函数。当选择为 True 的时候，表示求解对偶函数，如果样本量大于特征数目，建议求解原始拉格朗日函数，设定dual = False"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
